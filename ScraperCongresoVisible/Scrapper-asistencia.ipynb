{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping la asistencia de senadores en Feb~May 2018 usando datos de congresovisible.org \n",
    "Cada página tiene dos listas, una con la lista de senadores que votaron, la otra con la lista de los que se abstubieron. Como lo que queremos es determina si asistieron, ambos cuentan por igual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Para poder comparar facil después'''\n",
    "def elimina_tildes(cadena):\n",
    "    s = ''.join((c for c in unicodedata.normalize('NFD',cadena) if unicodedata.category(c) != 'Mn'))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Busca las listas de senadores'''\n",
    "def GetListSenators(soup):\n",
    "    \n",
    "    names = []\n",
    "\n",
    "    ## Votantes\n",
    "    table = soup.find('table', attrs={'id':'tabla-reporte-detallado'})\n",
    "    if table != None:\n",
    "        table_body = table.find('tbody')\n",
    "        rows = table_body.find_all('tr')\n",
    "\n",
    "        for row in rows:\n",
    "            name = row.find('td').get_text()\n",
    "            names.append(name)\n",
    "    \n",
    "    ## Abstenciones\n",
    "    table = soup.find('table', attrs={'id':'tabla-reporte-abstenciones'})\n",
    "    if table != None:\n",
    "        table_body = table.find('tbody')\n",
    "        rows = table_body.find_all('tr')\n",
    "\n",
    "        for row in rows:\n",
    "            name = row.find('td').get_text()\n",
    "            names.append(name)\n",
    "\n",
    "    ## Eliminar tildes\n",
    "    names = [elimina_tildes(name) for name in names ]\n",
    "    print(\"Found %d names\" % len(names))\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Busca la fecha en que se llevo a cabo la votación'''\n",
    "def GetDate(soup):\n",
    "    panel = soup.find_all(\"div\", attrs={\"class\": \"module-contenido\"})\n",
    "\n",
    "    ## Quick and dirty direct way\n",
    "    # print(panel[1].contents[1].contents[7].find('p').getText()) \n",
    "\n",
    "    for pan in panel:\n",
    "        for pa in pan.find_all('li'):\n",
    "            text = pa.find('p').get_text()\n",
    "            if \"201\" in text:\n",
    "                text = text.replace('d ','')\n",
    "                text = text.replace('de ','')\n",
    "                print(text)\n",
    "                return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Nov 30 2016\n",
      "Found 99 names\n"
     ]
    }
   ],
   "source": [
    "## Un ejemplo\n",
    "page = requests.get(\"https://www.congresovisible.org/votaciones/%d\" % 13960)\n",
    "print(page.status_code)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "date = GetDate(soup)\n",
    "senators = GetListSenators(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop sobre posibles paginas con resultados de votaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Busca votaciones en las URLs con el ID en el rango recibido'''\n",
    "def GetVotaciones(votaciones):\n",
    "    \n",
    "    for votacion in votaciones:\n",
    "        print(\"\\nVotacion %d\" % votacion)\n",
    "        page = requests.get(\"https://www.congresovisible.org/votaciones/%d\" % votacion)\n",
    "    \n",
    "        if page.status_code == 404:\n",
    "            print(\"Status code 404. Skipping....\")\n",
    "            continue\n",
    "    \n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        date = GetDate(soup)\n",
    "        senators = GetListSenators(soup)\n",
    "        df = pd.DataFrame({'senator':senators, 'date':date})\n",
    "        df = df.set_index('senator')\n",
    "        resultados.append(df)\n",
    "    \n",
    "        ## Save dataframe as csv\n",
    "        df.to_csv('votaciones/votacion_%d.csv' % votacion)\n",
    "    \n",
    "        ## Wait 1s to avoid hammering servers too much\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31 µs, sys: 16 µs, total: 47 µs\n",
      "Wall time: 57.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Rango de URLs que posiblemente tengan resultados de votaciones\n",
    "#votaciones = np.arange(13800,14000,1)\n",
    "rango_votaciones = np.arange(13953,14000,1)\n",
    "\n",
    "## Run it\n",
    "#GetVotaciones(rango_votaciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cada votación debe estar guardada en el folder `votaciones`  como un archivo csv con la fecha de la votación y la lista de senadores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
